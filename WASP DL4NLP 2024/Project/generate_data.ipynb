{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from typing import List, Optional\n",
    "\n",
    "def compute_diff(\n",
    "    buggy_code: str, fixed_code: str, context_len: Optional[int] = None\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Computes the diff between the buggy and fixed code.\n",
    "    \"\"\"\n",
    "    context_len = (\n",
    "        context_len\n",
    "        if context_len is not None\n",
    "        else max(len(buggy_code), len(fixed_code))\n",
    "    )\n",
    "    with open(\"/tmp/buggy.java\",\"w\") as f: f.write(buggy_code+\"\\n\")\n",
    "    with open(\"/tmp/fixed_code.java\",\"w\") as f: f.write(fixed_code+\"\\n\")\n",
    "    # we want to ignore whitespace changes with -w which does not exist in difflib.unified_diff\n",
    "    # with git diff, we even the name of the changed function in the diff, which helps a lot\n",
    "    cmd = [\"git\",\"diff\",\"--patience\",f\"-U{context_len}\", \"-w\",\"/tmp/buggy.java\",\"/tmp/fixed_code.java\"]\n",
    "    return subprocess.run(cmd, capture_output=True).stdout.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "megadiff_sf = load_dataset(\"ASSERT-KTH/megadiff-single-function\")\n",
    "megadiff_sf = megadiff_sf.map(lambda x: {\"short_diff\": compute_diff(x[\"buggy_function\"], x[\"fixed_function\"], context_len=3)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt(fixed_function: str) -> str:\n",
    "    return f\"\"\"\n",
    "### Fixed Function\n",
    "```java\n",
    "{fixed_function}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "def system_prompt() -> str:\n",
    "    return \"\"\"You are an assistant designed to help generate synthetic data for fine-tuning a language model for automatic program repair. You will receive a correctly implemented function as input. Your task is to generate:\n",
    "\n",
    "1. A buggy version of the provided function.\n",
    "2. A unit test method that exposes the behavioral difference between the buggy and fixed versions.\n",
    "3. The stack trace or error message resulting from executing that unit test method with the buggy function.\n",
    "\n",
    "Please ensure the following when generating the output:\n",
    "\n",
    "- The buggy function should have a realistic and plausible error that one might encounter in actual programming.\n",
    "- The unit test MUST be a method and directly target the introduced bug. ONLY the unit test method should be provided, not the entire test suite.\n",
    "- The stack trace or error message must be realistic and show the exact execution of the unit test.\n",
    "- Do NOT add any comment in the code about the bug, the bug injection or any other information.\n",
    "\n",
    "Format the output in the following structure:\n",
    "### Buggy Function\n",
    "```java\n",
    "<Buggy function code>\n",
    "```\n",
    "\n",
    "### Unit Test\n",
    "```java\n",
    "<Unit test code>\n",
    "```\n",
    "\n",
    "### Error Message or Stack Trace\n",
    "```\n",
    "<Error message or stack trace>\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "def user_prompt_v2(diff: str) -> str:\n",
    "    return f\"\"\"\n",
    "### Diff between fixed and buggy functions\n",
    "```diff\n",
    "{diff}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "def system_prompt_v2() -> str:\n",
    "    return \"\"\"You are an assistant designed to help generate synthetic data for fine-tuning a language model for automatic program repair. You will receive a bug-fixing diff as input. Your task is to generate:\n",
    "\n",
    "1. A unit test method that exposes the behavioral difference between the buggy and fixed versions.\n",
    "2. The stack trace or error message resulting from executing the unit test method.\n",
    "\n",
    "Please ensure the following when generating the output:\n",
    "\n",
    "- The unit test MUST be a method and directly target the introduced bug. ONLY the unit test method should be provided, not the entire test suite.\n",
    "- The stack trace or error message must be realistic and show the exact execution of the unit test.\n",
    "- Do NOT add any comment in the code about the bug, the bug injection or any other information.\n",
    "\n",
    "Format the output in the following structure:\n",
    "### Unit Test\n",
    "```java\n",
    "<Unit test code>\n",
    "```\n",
    "\n",
    "### Error Message or Stack Trace\n",
    "```\n",
    "<Error message or stack trace>\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "def call_openai(system_prompt: str, user_prompt: str, model: str = \"gpt-4o-mini\") -> str:\n",
    "    enc = tiktoken.encoding_for_model(model)\n",
    "    n_tokens = len(enc.encode(system_prompt)) + len(enc.encode(user_prompt))\n",
    "    if n_tokens >= 128000:\n",
    "        return None\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return completion\n",
    "\n",
    "def extract_output(completion):\n",
    "    \"\"\"\n",
    "    Extracts the output from the completion object.\n",
    "    \n",
    "    Returns:\n",
    "    - The generated buggy function\n",
    "    - The generated test case\n",
    "    - The generated test error or stack trace\n",
    "    \"\"\"\n",
    "    message = completion.choices[0].message.content\n",
    "\n",
    "    try:\n",
    "        buggy_function = message.split(\"### Buggy Function\")[1].split(\"```java\")[1].split(\"```\")[0].strip()\n",
    "        test_case = message.split(\"### Unit Test\")[1].split(\"```java\")[1].split(\"```\")[0].strip()\n",
    "        error_message = message.split(\"### Error Message or Stack Trace\")[1].split(\"```\")[1].strip()\n",
    "        return buggy_function, test_case, error_message\n",
    "    except Exception as e:\n",
    "        return None, None, None\n",
    "\n",
    "def extract_output_v2(completion):\n",
    "    \"\"\"\n",
    "    Extracts the output from the completion object.\n",
    "    \n",
    "    Returns:\n",
    "    - The generated test case\n",
    "    - The generated test error or stack trace\n",
    "    \"\"\"\n",
    "    message = completion.choices[0].message.content\n",
    "\n",
    "    try:\n",
    "        test_case = message.split(\"### Unit Test\")[1].split(\"```java\")[1].split(\"```\")[0].strip()\n",
    "        error_message = message.split(\"### Error Message or Stack Trace\")[1].split(\"```\")[1].strip()\n",
    "        return test_case, error_message\n",
    "    except Exception as e:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Bug\n",
      "diff --git a/tmp/buggy.java b/tmp/fixed_code.java\n",
      "index 0fd41ef..e61758b 100644\n",
      "--- a/tmp/buggy.java\n",
      "+++ b/tmp/fixed_code.java\n",
      "@@ -1,24 +1,24 @@\n",
      " private void ping() throws IOException, InterruptedException {\n",
      "         Future<?> f = channel.callAsync(new Ping());\n",
      "         long start = System.currentTimeMillis();\n",
      "         long end = start +timeout;\n",
      " \n",
      "         long remaining;\n",
      "         do {\n",
      "             remaining = end-System.currentTimeMillis();\n",
      "             try {\n",
      "-                f.get(Math.max(0,remaining),MILLISECONDS);\n",
      "+                f.get(remaining, MILLISECONDS);\n",
      "                 return;\n",
      "             } catch (ExecutionException e) {\n",
      "                 if (e.getCause() instanceof RequestAbortedException)\n",
      "                     return; // connection has shut down orderly.\n",
      "                 onDead(e);\n",
      "                 return;\n",
      "             } catch (TimeoutException e) {\n",
      "                 // get method waits \"at most the amount specified in the timeout\",\n",
      "                 // so let's make sure that it really waited enough\n",
      "             }\n",
      "         } while(remaining>0);\n",
      " \n",
      "         onDead(new TimeoutException(\"Ping started on \"+start+\" hasn't completed at \"+System.currentTimeMillis()));//.initCause(e)\n",
      "     }\n",
      "\n",
      "Generated Test Case\n",
      "@Test\n",
      "public void testPingTimeoutException() {\n",
      "    TimeoutException exception = assertThrows(TimeoutException.class, () -> {\n",
      "        BuggyClass buggyInstance = new BuggyClass();\n",
      "        buggyInstance.ping();\n",
      "    });\n",
      "    assertTrue(exception.getMessage().contains(\"Ping started on\"));\n",
      "}\n",
      "Generated Error Message\n",
      "java.util.concurrent.TimeoutException: Ping started on 1632628801000 hasn't completed at 1632628801005\n",
      "\tat BuggyClass.ping(BuggyClass.java:XX)\n",
      "\tat BuggyClassTest.testPingTimeoutException(BuggyClassTest.java:YY)\n"
     ]
    }
   ],
   "source": [
    "completion = call_openai(system_prompt(), user_prompt(megadiff_sf[\"train\"][0][\"fixed_function\"]), model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "buggy_function, test_case, error_message = extract_output(completion)\n",
    "\n",
    "diff = compute_diff(megadiff_sf[\"train\"][0][\"fixed_function\"].strip(), buggy_function.strip())\n",
    "\n",
    "print(\"Generated Bug\")\n",
    "print(diff)\n",
    "\n",
    "print(\"Generated Test Case\")\n",
    "print(test_case)\n",
    "\n",
    "print(\"Generated Error Message\")\n",
    "print(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff --git a/tmp/buggy.java b/tmp/fixed_code.java\n",
      "index 675f029..0289ad2 100644\n",
      "--- a/tmp/buggy.java\n",
      "+++ b/tmp/fixed_code.java\n",
      "@@ -7,13 +7,13 @@\n",
      "         boolean isBetter = false;\n",
      "         switch (policy) {\n",
      "             case MINIMIZE:\n",
      "-                if (bestVal > val) {\n",
      "+                if (bestVal > val || nbSol==1) {\n",
      "                     bestVal = val;\n",
      "                     isBetter = true;\n",
      "                 }\n",
      "                 break;\n",
      "             case MAXIMIZE:\n",
      "-                if (bestVal < val) {\n",
      "+                if (bestVal < val || nbSol==1) {\n",
      "                     bestVal = val;\n",
      "                     isBetter = true;\n",
      "                 }\n",
      "\n",
      "@Test\n",
      "public void testPolicyWithSingleSolution() {\n",
      "    double bestVal = 10.0;\n",
      "    double val = 5.0;\n",
      "    int nbSol = 1; // Only one solution\n",
      "    String policy = \"MINIMIZE\"; // Testing MINIMIZE policy\n",
      "\n",
      "    // Call the buggy version of the method\n",
      "    boolean result = buggyPolicyFunction(bestVal, val, nbSol, policy);\n",
      "\n",
      "    // Assert that the bestVal has been updated as expected\n",
      "    assertTrue(result);\n",
      "    assertEquals(5.0, bestVal, 0.001);\n",
      "}\n",
      "java.lang.AssertionError: expected [5.0] but found [10.0]\n",
      "\tat org.junit.Assert.assertEquals(Assert.java:115)\n",
      "\tat org.junit.Assert.assertEquals(Assert.java:144)\n",
      "\tat MyTestClass.testPolicyWithSingleSolution(MyTestClass.java:10)\n"
     ]
    }
   ],
   "source": [
    "completion = call_openai(system_prompt_v2(), user_prompt_v2(megadiff_sf[\"train\"][1][\"short_diff\"]), model=\"gpt-4o-mini\")\n",
    "test_case, error_message = extract_output_v2(completion)\n",
    "\n",
    "print(compute_diff(megadiff_sf[\"train\"][1][\"buggy_function\"], megadiff_sf[\"train\"][1][\"fixed_function\"], context_len=3))\n",
    "\n",
    "print(test_case)\n",
    "\n",
    "print(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/typing.py:392: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  def _eval_type(t, globalns, localns, recursive_guard=frozenset()):\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "completions = []\n",
    "tasks = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for i in range(len(megadiff_sf[\"train\"][:1000][\"short_diff\"])):\n",
    "        task = executor.submit(call_openai, system_prompt_v2(), user_prompt_v2(megadiff_sf[\"train\"][i][\"short_diff\"]), model=\"gpt-4o-mini\")\n",
    "        tasks.append(task)\n",
    "\n",
    "    completions = [future.result() for future in tasks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70475a4c7b9f4e9cb6ab9dcded226ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs = [extract_output_v2(completion) for completion in completions]\n",
    "\n",
    "megadiff_sf_plus = megadiff_sf[\"train\"].select(range(1000)).add_column(\"generated_test_case\", [output[0] for output in outputs]).add_column(\"generated_error_message\", [output[1] for output in outputs]).add_column(\"completion\", [completion for completion in completions])\n",
    "megadiff_sf_plus.save_to_disk(\"megadiff_sf_plus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "megadiff_sf_plus = load_from_disk(\"megadiff_sf_plus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(buggy_code: str, failing_test_case: str, failing_test_case_error: str) -> str:\n",
    "    return f\"\"\"You are an automatic program repair tool. Your task is to fix the provided buggy code.\n",
    "\n",
    "The following code contains a buggy function:\n",
    "```java\n",
    "{buggy_code}\n",
    "```\n",
    "\n",
    "The code fails the following test:\n",
    "```java\n",
    "{failing_test_case}\n",
    "```\n",
    "\n",
    "With the following test error:\n",
    "```\n",
    "{failing_test_case_error}\n",
    "```\n",
    "\n",
    "Please provide a fixed version of the buggy function, and only that function:\n",
    "\"\"\"\n",
    "\n",
    "def build_answer(fixed_code: str) -> str:\n",
    "    return f\"```java\\n{fixed_code}\\n```\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bbfad98bdbd42cd94ae53fb1c59d97a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/72393 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75afce392da40d688e89cbad694dbeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/72393 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create new columns with the prompt and answer\n",
    "megadiff_sf_plus = megadiff_sf_plus.map(lambda x: {\"prompt\": build_prompt(x[\"buggy_function\"], x[\"generated_test_case\"], x[\"generated_error_message\"])})\n",
    "megadiff_sf_plus = megadiff_sf_plus.map(lambda x: {\"answer\": build_answer(x[\"fixed_function\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an automatic program repair tool. Your task is to fix the provided buggy code.\n",
      "\n",
      "The following code contains a buggy function:\n",
      "```java\n",
      "    private void ping() throws IOException, InterruptedException {\n",
      "        Future<?> f = channel.callAsync(new Ping());\n",
      "        long start = System.currentTimeMillis();\n",
      "        long end = start +timeout;\n",
      "\n",
      "        long remaining;\n",
      "        do {\n",
      "            remaining = end-System.currentTimeMillis();\n",
      "            try {\n",
      "                f.get(Math.max(0,remaining),MILLISECONDS);\n",
      "                return;\n",
      "            } catch (ExecutionException e) {\n",
      "                if (e.getCause() instanceof RequestAbortedException)\n",
      "                    return; // connection has shut down orderly.\n",
      "                onDead(e);\n",
      "                return;\n",
      "            } catch (TimeoutException e) {\n",
      "                // get method waits \"at most the amount specified in the timeout\",\n",
      "                // so let's make sure that it really waited enough\n",
      "            }\n",
      "        } while(remaining>0);\n",
      "\n",
      "        onDead(new TimeoutException(\"Ping started on \"+start+\" hasn't completed at \"+System.currentTimeMillis()).initCause(e));\n",
      "    }\n",
      "\n",
      "```\n",
      "\n",
      "The code fails the following test:\n",
      "```java\n",
      "import static org.junit.jupiter.api.Assertions.*;\n",
      "import org.junit.jupiter.api.Test;\n",
      "import java.util.concurrent.TimeoutException;\n",
      "\n",
      "public class PingTest {\n",
      "\n",
      "    @Test\n",
      "    public void testPingTimeoutException() {\n",
      "        Ping ping = new Ping();\n",
      "        long startTime = System.currentTimeMillis();\n",
      "        \n",
      "        Exception exception = assertThrows(TimeoutException.class, () -> {\n",
      "            ping.startPing(); // This method would need to simulate a timeout\n",
      "        });\n",
      "\n",
      "        String expectedMessage = \"Ping started on \" + startTime + \" hasn't completed at \" + System.currentTimeMillis();\n",
      "        String actualMessage = exception.getMessage();\n",
      "\n",
      "        assertTrue(actualMessage.contains(expectedMessage));\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "With the following test error:\n",
      "```\n",
      "org.junit.jupiter.api.Assertions$AssertionFailedError: \n",
      "Expected message to contain \"Ping started on 1669292000000 hasn't completed at 1669292001000\" but was \"Ping started on 1669292000000 hasn't completed at 1669292001000\". \n",
      "Expected :Ping started on 1669292000000 hasn't completed at 1669292001000\n",
      "Actual   :Ping started on 1669292000000 hasn't completed at 1669292001000\n",
      "\tat org.junit.jupiter.api.Assert.fail(Assert.java:138)\n",
      "\tat org.junit.jupiter.api.Assertions.assertTrue(Assertions.java:1257)\n",
      "\tat org.junit.jupiter.api.Assertions.assertTrue(Assertions.java:1280)\n",
      "\tat PingTest.testPingTimeoutException(PingTest.java:12)\n",
      "```\n",
      "\n",
      "Please provide a fixed version of the buggy function, and only that function:\n",
      "\n",
      "```java\n",
      "    private void ping() throws IOException, InterruptedException {\n",
      "        Future<?> f = channel.callAsync(new Ping());\n",
      "        long start = System.currentTimeMillis();\n",
      "        long end = start +timeout;\n",
      "\n",
      "        long remaining;\n",
      "        do {\n",
      "            remaining = end-System.currentTimeMillis();\n",
      "            try {\n",
      "                f.get(Math.max(0,remaining),MILLISECONDS);\n",
      "                return;\n",
      "            } catch (ExecutionException e) {\n",
      "                if (e.getCause() instanceof RequestAbortedException)\n",
      "                    return; // connection has shut down orderly.\n",
      "                onDead(e);\n",
      "                return;\n",
      "            } catch (TimeoutException e) {\n",
      "                // get method waits \"at most the amount specified in the timeout\",\n",
      "                // so let's make sure that it really waited enough\n",
      "            }\n",
      "        } while(remaining>0);\n",
      "\n",
      "        onDead(new TimeoutException(\"Ping started on \"+start+\" hasn't completed at \"+System.currentTimeMillis()));//.initCause(e)\n",
      "    }\n",
      "\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(megadiff_sf_plus[0][\"prompt\"])\n",
    "print(megadiff_sf_plus[0][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403f3f9192e5469e8df31fa8b8cd5d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/6 shards):   0%|          | 0/72393 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "megadiff_sf_plus.save_to_disk(\"megadiff_sf_plus_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "megadiff_sf_plus = load_from_disk(\"megadiff_sf_plus_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates (short_diff): 6277\n",
      "Number of duplicates (prompt): 0\n"
     ]
    }
   ],
   "source": [
    "# Deduplicate the dataset based on the exact match the short_diff and prompt\n",
    "from functools import partial\n",
    "\n",
    "def is_unique(elem , column: str, memory: set) -> bool:\n",
    "    if elem[column] in memory:\n",
    "        return False\n",
    "    else:\n",
    "        memory.add(elem[column])\n",
    "        return True\n",
    "\n",
    "memory = set()\n",
    "megadiff_sf_plus_shortdiff_exactdedup = megadiff_sf_plus.filter(partial(is_unique, column=\"short_diff\", memory=memory))\n",
    "\n",
    "print(f\"Number of duplicates (short_diff): {len(megadiff_sf_plus) - len(megadiff_sf_plus_shortdiff_exactdedup)}\")\n",
    "\n",
    "memory = set()\n",
    "megadiff_sf_plus_prompt_exactdedup = megadiff_sf_plus_shortdiff_exactdedup.filter(partial(is_unique, column=\"prompt\", memory=memory))\n",
    "\n",
    "print(f\"Number of duplicates (prompt): {len(megadiff_sf_plus_shortdiff_exactdedup) - len(megadiff_sf_plus_prompt_exactdedup)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class Shingler:\n",
    "    def __init__(self, k: int = 3):\n",
    "        self.k = k\n",
    "        # A very approximate tokenization for most programming languages\n",
    "        self.NON_ALPHA = re.compile(\"[^A-Za-z_0-9]\")\n",
    "\n",
    "    def __process_doc(self, document):\n",
    "        return [t for t in self.NON_ALPHA.split(document) if len(t.strip()) > 0]\n",
    "\n",
    "    def get_shingles(self, document):\n",
    "        shingles = set()\n",
    "        document = self.__process_doc(document)\n",
    "        for i in range(0, len(document)-self.k+1 ):\n",
    "            shingles.add(\" \".join(document[i:i+self.k]))\n",
    "        return shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import MinHash\n",
    "\n",
    "import tqdm\n",
    "\n",
    "min_hashes = []\n",
    "\n",
    "# Compute minhashes for the prompt\n",
    "for i, row in tqdm.tqdm(enumerate(megadiff_sf_plus_prompt_exactdedup), total=len(megadiff_sf_plus_prompt_exactdedup)):\n",
    "    min_hash = MinHash(num_perm=128)\n",
    "    shingles = Shingler().get_shingles(row[\"prompt\"])\n",
    "    for shingle in shingles:\n",
    "        min_hash.update(shingle.encode('utf-8'))\n",
    "    min_hashes.append(min_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 4470\n"
     ]
    }
   ],
   "source": [
    "from datasketch import MinHashLSH\n",
    "\n",
    "lsh = MinHashLSH(threshold=0.85, num_perm=128)\n",
    "\n",
    "for i, min_hash in enumerate(min_hashes):\n",
    "    lsh.insert(i, min_hash)\n",
    "\n",
    "prompt_duplicates = []\n",
    "for i, min_hash in enumerate(min_hashes):\n",
    "    idxs = lsh.query(min_hash)\n",
    "    if len(idxs) > 1:\n",
    "        prompt_duplicates.append(idxs)\n",
    "\n",
    "print(f\"Number of duplicates: {sum(len(dups) for dups in prompt_duplicates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66116/66116 [01:08<00:00, 962.87it/s]\n"
     ]
    }
   ],
   "source": [
    "short_diff_min_hashes = []\n",
    "\n",
    "# Compute minhashes for the short_diff\n",
    "for i, row in tqdm.tqdm(enumerate(megadiff_sf_plus_prompt_exactdedup), total=len(megadiff_sf_plus_prompt_exactdedup)):\n",
    "    min_hash = MinHash(num_perm=128)\n",
    "    shingles = Shingler().get_shingles(row[\"short_diff\"])\n",
    "    for shingle in shingles:\n",
    "        min_hash.update(shingle.encode('utf-8'))\n",
    "    short_diff_min_hashes.append(min_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 774\n"
     ]
    }
   ],
   "source": [
    "lsh = MinHashLSH(threshold=0.85, num_perm=128)\n",
    "\n",
    "for i, min_hash in enumerate(short_diff_min_hashes):\n",
    "    lsh.insert(i, min_hash)\n",
    "\n",
    "shortdiff_duplicates = []\n",
    "for i, min_hash in enumerate(short_diff_min_hashes):\n",
    "    idxs = lsh.query(min_hash)\n",
    "    if len(idxs) > 1:\n",
    "        shortdiff_duplicates.append(idxs)\n",
    "\n",
    "print(f\"Number of duplicates: {sum(len(dups) for dups in shortdiff_duplicates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f44401d203d4333ab8235def3b0ee1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/5 shards):   0%|          | 0/64388 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove all samples that are duplicated (naive approach)\n",
    "duplicates = set(sum(prompt_duplicates, [])) | set(sum(shortdiff_duplicates, []))\n",
    "\n",
    "megadiff_sf_plus_dedup = megadiff_sf_plus_prompt_exactdedup.select(\n",
    "    [i for i in range(len(megadiff_sf_plus_prompt_exactdedup)) if i not in duplicates]\n",
    ")\n",
    "\n",
    "megadiff_sf_plus_dedup.save_to_disk(\"megadiff_sf_plus_dedup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d16e354090bd4e2493afd04d524b0563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7cb1573dd7455ba72281888a2a2225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0d8683b1c445d594060992218a41aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a482627382b7438b8e0c166107cd1d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b578a5cec1b49a58c7a4b566de4ae39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05f0e0beafb482dbb575b7f1fc73f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/ASSERT-KTH/megadiff-sf-synthetic_test_error/commit/ac8f2cbc294c4b37f8c71560b5684bcd1644e741', commit_message='Upload dataset', commit_description='', oid='ac8f2cbc294c4b37f8c71560b5684bcd1644e741', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "megadiff_sf_plus_dedup.push_to_hub(\"ASSERT-KTH/megadiff-sf-synthetic_test_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f85d207603945b3b5de95a819a329dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/64388 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "import re\n",
    "\n",
    "ds = load_from_disk(\"megadiff_sf_plus_dedup\")\n",
    "\n",
    "# remove comments from answer\n",
    "def remove_java_comments(source: str) -> str:\n",
    "    # Define states\n",
    "    NORMAL, SINGLE_COMMENT, MULTI_COMMENT, STRING_LITERAL, CHAR_LITERAL = range(5)\n",
    "\n",
    "    state = NORMAL\n",
    "    result = []\n",
    "    i = 0\n",
    "\n",
    "    while i < len(source):\n",
    "        # Check the current state and process accordingly\n",
    "        if state == NORMAL:\n",
    "            if source[i : i + 2] == \"//\":\n",
    "                state = SINGLE_COMMENT\n",
    "                i += 2\n",
    "            elif source[i : i + 2] == \"/*\":\n",
    "                state = MULTI_COMMENT\n",
    "                i += 2\n",
    "            elif source[i] == '\"':\n",
    "                state = STRING_LITERAL\n",
    "                result.append(source[i])\n",
    "                i += 1\n",
    "            elif source[i] == \"'\":\n",
    "                state = CHAR_LITERAL\n",
    "                result.append(source[i])\n",
    "                i += 1\n",
    "            else:\n",
    "                result.append(source[i])\n",
    "                i += 1\n",
    "        elif state == SINGLE_COMMENT:\n",
    "            if source[i] == \"\\n\":\n",
    "                state = NORMAL\n",
    "                result.append(source[i])\n",
    "                i += 1\n",
    "            else:\n",
    "                i += 1\n",
    "        elif state == MULTI_COMMENT:\n",
    "            if source[i : i + 2] == \"*/\":\n",
    "                state = NORMAL\n",
    "                i += 2\n",
    "            else:\n",
    "                i += 1\n",
    "        elif state == STRING_LITERAL:\n",
    "            if source[i] == \"\\\\\":\n",
    "                result.append(source[i])\n",
    "                i += 1\n",
    "                result.append(source[i])\n",
    "                i += 1\n",
    "            elif source[i] == '\"':\n",
    "                state = NORMAL\n",
    "                result.append(source[i])\n",
    "                i += 1\n",
    "            else:\n",
    "                result.append(source[i])\n",
    "                i += 1\n",
    "        elif state == CHAR_LITERAL:\n",
    "            if source[i] == \"\\\\\":\n",
    "                result.append(source[i])\n",
    "                i += 1\n",
    "                result.append(source[i])\n",
    "                i += 1\n",
    "            elif source[i] == \"'\":\n",
    "                state = NORMAL\n",
    "                result.append(source[i])\n",
    "                i += 1\n",
    "            else:\n",
    "                result.append(source[i])\n",
    "                i += 1\n",
    "\n",
    "    return \"\".join(result)\n",
    "\n",
    "def remove_empty_lines(source):\n",
    "    \"\"\"Remove all empty lines from Java source code.\"\"\"\n",
    "    return re.sub(r\"^\\s*$\\n\", \"\", source, flags=re.MULTILINE)\n",
    "\n",
    "ds_no_comments = ds.map(lambda x: {\"answer\": \"```java\\n\" + remove_empty_lines(remove_java_comments(x[\"answer\"].split(\"```java\")[1].split(\"```\")[0])) + \"```\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b5eeb6980c4e1380f2a7705c880e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9275e37e512f42bea82d5071b1effdf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/17 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e36b986de049e18f7864097c27ef8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/17 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e2b1053baf48c6bee450e25ef9d885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/17 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3271485108b24ef08bea626013cc2e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/17 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/ASSERT-KTH/megadiff-sf-synthetic_test_error_no_comments/commit/d3114a397ac24e0dce1c69789b439a91f2d7ce34', commit_message='Upload dataset', commit_description='', oid='d3114a397ac24e0dce1c69789b439a91f2d7ce34', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_no_comments.push_to_hub(\"ASSERT-KTH/megadiff-sf-synthetic_test_error_no_comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
